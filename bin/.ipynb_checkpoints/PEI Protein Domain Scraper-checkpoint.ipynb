{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEI Domain Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Formatting\n",
    "import re\n",
    "import os\n",
    "import pprint\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import HTML\n",
    "import selenium.webdriver as webdriver\n",
    "\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape all pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 pages found\n",
      "CPU times: user 24.4 s, sys: 412 ms, total: 24.8 s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pages = []\n",
    "\n",
    "for page in range(204):\n",
    "    response = requests.get(\"https://www.genscript.com/gene/9606/homo-sapiens?page=\"+str(page+1))\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    pages.append(soup.find_all(class_='link_main'))\n",
    "\n",
    "print(f'{len(pages)} pages found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape all links from pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20302 links found\n",
      "CPU times: user 429 ms, sys: 14.3 ms, total: 444 ms\n",
      "Wall time: 474 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "      \n",
    "all_links = list(set([link for page in pages for link in page]))\n",
    "print(f'{len(all_links)} links found')\n",
    "\n",
    "full_urls = []\n",
    "for link in all_links:\n",
    "    base_url = \"https://www.genscript.com\"\n",
    "    full_urls.append(base_url + link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get ORF Nucleotide Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGGCGCTGC GGCACCTCGC CCTCCTGGCT GGCCTTCTCG TGGGAGTCGC CAGCAAGTCC \n",
      "ATGGAGAACA CGGTCACGAG AAACAGCACA GCTGTGATCA ACACACAAGC TGAGGGTACC \n",
      "CTGAGCCCCC CAGGCCTGTC CAGTCTGCCT GTGGTCAGGG AATGGGCCCT CACACACACC \n",
      "GCCCAGCTGC CCGAGTGCTG TGTGGATGTG GTGGGCGTCA ACGCCAGCTG CCCAGGCGCA \n",
      "AGTCTGTGTG GTCCAGGCTG TTACAGGCGC TGGAACGCGG ACGGGAGCGC CAGCTGCGTC \n",
      "CGCTGTGGGA ACGGAACCCT CCCAGCCTAC AACGGCTCCG AGTGTAGAAG CTTTGCTGGC \n",
      "CCGGGTGCGC CATTCCCCAT GAACAGAAGC TCAGGGACCC CCGGGCGGCC ACATCCTGGG \n",
      "GCTCCGCGCG TGGCCGCCTC CCTCTTCCTG GGCACGTTCT TCATTAGCTC CGGCCTCATC \n",
      "CTCTCCGTAG CTGGGTTCTT CTACCTCAAG CGCTCCAGTA AACTCCCCAG GGCCTGCTAC \n",
      "AGAAGAAACA AAGCTCCGGC CCTGCAGCCT GGCGAAGCCG CTGCAATGAT CCCCCCGCCA \n",
      "CAGTCCTCAG GTAACAGCAG CTGTCGCATC CCCCTGTGGG GTTTCCCATC TCTGGGCCAG \n",
      "TCCCAGGGTG CTCTGTGGGT TTGTCCCCAA ACGGGTTTGC CTGGCTCTGG ATCTCGGCCA \n",
      "CCCCTGCCCG GGTCCCCAGG AGACCCACCC ACAAGGCAGG GCCAGGGCCG GATTTGGCTG \n",
      "GTGCCCCCTG CTCTGGATCT CAGCTGGATT TGGCCGGCGC CCCCTGCCCG CCCCCCTTTA \n",
      "ATCCCCGTGA CTTCCATGCT CTTTCCTGTT CCCGAGACGT GGGGTCTGCA GGAAAGGAGG \n",
      "ACCCACCACG ACAGGGCAGA CCCCCAATAC CTGCTCCTCC TTGAAGTCCA GCTCCACCCG \n",
      "AGGACAGACG CAGCCGGCCT CCGCCAGGCC CTCCTGAGCA GCCATCGCTT CAGTGGTGCT \n",
      "GGGTCAGGCG GACCCAAGAG TCAGCCCGTA CGGAAGCCGC GCTACGTCAG GCGGGAGCGG \n",
      "CCCCTGGACA GGGCCACGGA TCCCGCTGCC TTCCCGGGGG AGGCCCGTAT CAGCAATGTC \n",
      "TGA\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), \"chromedriver\")\n",
    "driver = webdriver.Chrome(dirname)\n",
    "driver.get(full_urls[4]) ## TODO: for loop\n",
    "\n",
    "sequence_links = driver.find_element_by_partial_link_text(\"ORF Nucleotide Sequence\")\n",
    "onclick = sequence_links.get_attribute(\"onclick\")\n",
    "sequence_id = re.search(r'#(\\w*)', onclick).group(1)\n",
    "\n",
    "driver.execute_script('$(\"#' + sequence_id + '\").dialog({width:740,height:400})')\n",
    "\n",
    "sequence_table = driver.find_element_by_id(sequence_id)\n",
    "gene_sequence = sequence_table.find_elements_by_tag_name('td')\n",
    "print(gene_sequence[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Clean lists\n",
    "flat_list = [item for sublist in l for item in sublist]\n",
    "flat_uniq = list(set(flat_list))\n",
    "flat_in   = flat_uniq\n",
    "base_url = \"https://www.genscript.com\"\n",
    "\n",
    "import selenium.webdriver as webdriver\n",
    "dirname = os.path.join(os.getcwd(), \"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(dirname)\n",
    "\n",
    "for key in flat_in:\n",
    "    post_url = key.get('href')\n",
    "    request = requests.get(base_url + post_url)\n",
    "    \n",
    "driver.get(full_url)\n",
    "    \n",
    "html_from_page = driver.page_source\n",
    "\n",
    "soup = bs4.BeautifulSoup(html_from_page, 'html.parser')\n",
    "onclicks = soup.find_all('a', attrs={'href': '#orf'})\n",
    "onclicks\n",
    "\n",
    "buttons = driver.find_elements_by_name('booksubmit')\n",
    "for button in buttons:\n",
    "    onclick_text = button.get_attribute('onclick')\n",
    "    if onclick_text and re.search('Bedroom Deluxe', onclick_text):\n",
    "        print \"found it!\"\n",
    "        button.click()\n",
    "     \n",
    "        soup = BeautifulSoup(request.text, 'html.parser')\n",
    "\n",
    "html_from_page = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> 3. Scrape Metadata for Input Proteins </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for protein in d[ref_name]:\n",
    "    # Make Request\n",
    "    req = requests.get(url + protein + suffix, headers)\n",
    "    l.append(req.text)\n",
    "    print(url + protein + suffix)\n",
    "    print(\"Success for \" + protein + \" \" +)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> 4. Generate, Clean, and Output CSV </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Original fasta cleaner (gets rid of empty lines and such), not very effective\n",
    "ll = [x.replace(\"\\r\\n\", \"<\") for x in l]\n",
    "d[\"SCRAPE\"] = l\n",
    "d.to_excel(os.path.join(dirname, \"output2.xlsx\"), index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NextProt Scraper using XML accession\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "seq  = []\n",
    "code = []\n",
    "iso  = []\n",
    "can  = []\n",
    "name = []\n",
    "\n",
    "for protein in d[ref_name]:\n",
    "    req = requests.get(url + protein + suffix, headers)\n",
    "    tree = ElementTree.fromstring(req.content)\n",
    "    print(protein)\n",
    "    v = tree[0]\n",
    "    n = len(v)\n",
    "\n",
    "    for i in range(n):\n",
    "        seq.append(v[i].text)\n",
    "        code.append(v[i].attrib['accession'])\n",
    "        iso.append(v[i].attrib['name'])\n",
    "        name.append(tree.attrib['accession'])\n",
    "        \n",
    "        if 'canonical-isoform' in v[i].attrib:\n",
    "            can.append(True)\n",
    "        else:\n",
    "            can.append(False)\n",
    "\n",
    "l = p.DataFrame(list(zip(code, name, iso, can, seq)), columns =['Code', 'Name', 'Isoform', 'Canonical', 'Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "l = p.DataFrame(list(zip(name, code, iso, can, seq)), columns =['Name', 'Code', 'Isoform', 'Canonical', 'Sequence'])\n",
    "l.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coronavirus Sequences (tbl format)\n",
    "\n",
    "covseq = os.path.join(dirname, \"taxid11118.acc_lst\")\n",
    "cv = p.read_csv(covseq, header = None, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "l = p.DataFrame(list(zip(name, code, iso, can, seq)), columns =['Name', 'Code', 'Isoform', 'Canonical', 'Sequence'])\n",
    "l.to_csv(\"output_covid_seqs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as p\n",
    "\n",
    "def fasta_parse(fasta_file_name, export = False, export_name = \"output.csv\"):\n",
    "\n",
    "    with open(fasta_file_name) as fasta_file:\n",
    "        idx = []\n",
    "        seqs = []\n",
    "        name = []\n",
    "        lens = []\n",
    "        descs = []\n",
    "        for seq_record in SeqIO.parse(fasta_file, 'fasta'):  # (generator)\n",
    "            idx.append(seq_record.id)\n",
    "            name.append(seq_record.name)\n",
    "            descs.append(seq_record.description)\n",
    "            seqs.append(str(seq_record.seq))\n",
    "            lens.append(len(str(seq_record.seq)))\n",
    "\n",
    "        df_out = p.DataFrame(list(zip(name, idx, descs, seqs, lens)), columns =['Name', 'ID', 'Description', 'Sequence', 'Length'])\n",
    "        \n",
    "        if export:\n",
    "            df_out.to_csv(export_name)\n",
    "            \n",
    "        return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "c_out = p.DataFrame(list(zip(name, idx, seqs, lens)), columns =['Name', 'ID', 'Sequence', 'Length'])\n",
    "c_out.to_csv(\"c_output2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(seq_record)\n",
    "seq_record.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orfipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install orfipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import orfipy_core \n",
    "\n",
    "data = os.path.join(dirname, \"coronavirus_complete_genome.csv\")\n",
    "v = p.read_csv(data, skiprows = 0, sep=',')\n",
    "\n",
    "names   = []\n",
    "ids     = []\n",
    "starts  = []\n",
    "stops   = []\n",
    "strands = []\n",
    "descs   = []\n",
    "\n",
    "for i in range(len(v)):\n",
    "    for start,stop,strand,description in orfipy_core.orfs(v.iloc[i][\"Sequence\"]):\n",
    "        names.append(v.iloc[i][\"Name\"])\n",
    "        ids.append(v.iloc[i][\"ID\"])\n",
    "        starts.append(start)\n",
    "        stops.append(stop)\n",
    "        strands.append(strand)\n",
    "        descs.append(description)\n",
    "        print(start,stop,strand,description)\n",
    "    \n",
    "# Export\n",
    "c_out = p.DataFrame(list(zip(names, ids, starts, stops, strands, descs)), columns =['Name', 'ID', 'Start', 'Stop', 'Strand', 'Description'])\n",
    "c_out.to_csv(\"orfs_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NextProt Scraper using XML accession\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "url = \"https://www.ncbi.nlm.nih.gov/nuccore/\"\n",
    "\n",
    "seq  = []\n",
    "code = []\n",
    "iso  = []\n",
    "can  = []\n",
    "name = []\n",
    "\n",
    "for protein in d[ref_name]:\n",
    "    req = requests.get(url + protein + suffix, headers)\n",
    "    tree = ElementTree.fromstring(req.content)\n",
    "    print(protein)\n",
    "    v = tree[0]\n",
    "    n = len(v)\n",
    "\n",
    "    for i in range(n):\n",
    "        seq.append(v[i].text)\n",
    "        code.append(v[i].attrib['accession'])\n",
    "        iso.append(v[i].attrib['name'])\n",
    "        name.append(tree.attrib['accession'])\n",
    "        \n",
    "        if 'canonical-isoform' in v[i].attrib:\n",
    "            can.append(True)\n",
    "        else:\n",
    "            can.append(False)\n",
    "\n",
    "l = p.DataFrame(list(zip(code, name, iso, can, seq)), columns =['Code', 'Name', 'Isoform', 'Canonical', 'Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "\n",
    "url = \"https://www.ncbi.nlm.nih.gov/nuccore/\"\n",
    "\n",
    "data = os.path.join(dirname, \"covid_input.csv\")\n",
    "d = p.read_csv(data, skiprows = 0, sep=',')\n",
    "\n",
    "for protein in d[\"Accession\"]:\n",
    "    print(protein)\n",
    "    req = requests.get(url + protein, headers)\n",
    "    tree = ElementTree.fromstring(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entrezpy.conduit\n",
    "c = entrezpy.conduit.Conduit('brosenthal@pei.bio')\n",
    "c.api_envar = 'ba0f01f79a86fb4f6133116cb1ccc5b27808'\n",
    "\n",
    "fetch_influenza = c.new_pipeline()\n",
    "sid = fetch_influenza.add_search({'db' : 'nucleotide', 'term' : 'H3N2 [organism] AND HA', 'rettype':'count', 'sort' : 'Date Released', 'mindate': 2000, 'maxdate':2019, 'datetype' : 'pdat'})\n",
    "fid = fetch_influenza.add_fetch({'retmax' : 10, 'retmode' : 'text', 'rettype': 'fasta'}, dependency=sid)\n",
    "\n",
    "e = entrezpy.efetch.efetcher.Efetcher(tool,\n",
    "                                      email,\n",
    "                                      apikey=None,\n",
    "                                      apikey_var=None,\n",
    "                                      threads=None,\n",
    "                                      qid=None)\n",
    "analyzer = e.inquire({'db' : 'pubmed',\n",
    "                      'id' : [17284678, 9997],\n",
    "                      'retmode' : 'text',\n",
    "                      'rettype' : 'abstract'})\n",
    "print(analyzer.count, analyzer.retmax, analyzer.retstart, analyzer.uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install entrezpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entrezpy.conduit\n",
    "import os\n",
    "\n",
    "c = entrezpy.conduit.Conduit(\n",
    "    email = 'brosenthal@pei.bio',\n",
    "    apikey = 'ba0f01f79a86fb4f6133116cb1ccc5b27808')\n",
    "c.api_envar = ''\n",
    "\n",
    "c = entrezpy.conduit.Conduit('brosenthal@pei.bio')\n",
    "d = entrezpy.efetch(db=\"nuccore\", id=list(d.Accession)[1] , rettype='fasta_cds_na', retmode=\"text\")\n",
    "\n",
    "Entrez.efetch(db=datatype,id=ncid,rettype='gb')\n",
    "fid = get_covid.add_fetch({'db': 'nuccore', 'id': list(d.Accession), 'retmode' : 'text', 'rettype' : 'fasta_cds_na'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrez_query = es.inquire(\n",
    "        {'db': 'nuccore',\n",
    "         'id': list(d.Accession),\n",
    "         'rettype': 'fasta_cds_na'})\n",
    "query = get_covid.inquire({'db':'nuccore', 'id': list(d.Accession)})\n",
    "\n",
    "entrez_uids = entrez_query.get_result().uids\n",
    "\n",
    "%tb\n",
    "=Entrez.efetch(db=\"genome\", id=6863, rettype=\"gb\", retmode=\"text\")\n",
    "\n",
    ".add_fetch({'db':'nuccore', 'id': list(d.Accession), 'retmode' : 'text', 'rettype' : 'fasta_cds_na'})\n",
    "\n",
    "type(sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrezpy.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrezpy.efetch.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(d.Accession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'brosenthal@pei.bio'\n",
    "apikey = 'ba0f01f79a86fb4f6133116cb1ccc5b27808'\n",
    "e = entrezpy.efetch.efetcher.Efetcher('efetcher', email, apikey)\n",
    "a = e.inquire({'db' : 'nuccore','id' : list(d.Accession), 'retmode':'text', 'rettype': 'fasta_cds_na'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea = entrezpy.efetch.efetch_analyzer.EfetchAnalyzer\n",
    "a.convert_response(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "\n",
    "d = pd.read_csv(os.path.join(dirname, \"seqs_old_sars.csv\"))\n",
    "Entrez.email = email\n",
    "Entrez.apikey = apikey\n",
    "handle = Entrez.efetch(db = 'nuccore', id = list(d.Accession), retmode = 'xml', rettype = 'fasta_cds_na')\n",
    "\n",
    "with open('output_temp.fasta', 'w') as outfile:\n",
    "    outfile.write(handle.read())\n",
    "    \n",
    "fasta_parse('output_temp.fasta').to_csv('output_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import math\n",
    "\n",
    "def entrezpyConvert(self, ids):\n",
    "\n",
    "    try:\n",
    "        self.file = tempfile.NamedTemporaryFile()\n",
    "        fetch_handle = entrezpy.efetch(db=\"nuccore\", id=ids, rettype=\"fasta_cds_na\", retmode=\"text\")\n",
    "\n",
    "        for i in range(int(math.ceil(float(len(ids)) / 5000))):\n",
    "\n",
    "            start = i * 5000\n",
    "            remaining = len(self.nuc_seq_ids) - start\n",
    "            end = start + remaining if remaining < 5000 else start + 5000\n",
    "\n",
    "            fetch_handle = entrezpy.efetch(db=\"nuccore\", id=self.nuc_seq_ids[start:end], rettype=\"fasta_cds_na\", retmode=\"text\")\n",
    "\n",
    "            for line in fetch_handle:\n",
    "                self.file.write(line)\n",
    "\n",
    "            fetch_handle.close() \n",
    "            self.file.seek(0)\n",
    "\n",
    "    except IOError:\n",
    "            raise TaskError(\"Could not download sequence from NCBI\")\n",
    "\n",
    "    self.filepath = self.file.name\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrezpyConvert(a, list(d.Accession))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrezpy.efetch(db=\"nuccore\", id=ids, rettype=\"fasta_cds_na\", retmode=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(d.Accession)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrezpy.efetch(db=\"nuccore\", id=ids, rettype=\"fasta_cds_na\", retmode=\"text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
